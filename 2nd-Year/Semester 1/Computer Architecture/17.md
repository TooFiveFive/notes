# Lecture 17
*13/11/2019*

## Direct Mapped Cache Alternatives
### Reducing Miss Rate
- **Fully associative caches**: Any block can go to any cache
    - To find the block you have to search whole cache

    - Search all entries at once to reduce hit time (additional HW required)

- **n-way set-associative cache**
    - A block can be located to a set on n cache blocks

    - Use a *Memory Block Number* to define which set a block belongs to.

    - *Which Block?*: any in the set

    - Search all entries in set at once (some additional HW still required)

    - This will require less HW than other option

    - Less data reuired than direct mapped cache as no block position reuired.

### Set Associative Cache
- Use AND of tag and address as selection line.

- This is then passed through a multiplexer to select the right set for searching

- *Cache Index*: relative index in set.

- *Block Index*: Index of block in relation to cache.

### Replacing blocks
- In cache, we use *Least Recently Used* to find the block which will be replaced with another block in cache.

- In Set Associative Cache, *LRU* is applied exclusively within the destination set.

## Improving cache performance
- Use Multi Level Cache

- **L1**: 2 to 64KB (x cycles)

- **L2**: ~2MB (3x cycles)

- **L3**: ~8MB (9x cycles)

- *Main Memory*: ~30x cycles
